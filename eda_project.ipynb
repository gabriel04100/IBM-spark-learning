{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./.venv/lib/python3.11/site-packages (3.5.2)\n",
      "Requirement already satisfied: findspark in ./.venv/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: wget in ./.venv/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.venv/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pyspark  findspark wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the SparkContext.   \n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 22:57:18 WARN Utils: Your hostname, gabriel-BOD-WXX9 resolves to a loopback address: 127.0.1.1; using 192.168.204.211 instead (on interface wlp0s20f3)\n",
      "24/09/23 22:57:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/23 22:57:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a SparkContext object  \n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Creating a SparkSession  \n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark DataFrames basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'employees (1).csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download the CSV data first into a local `employees.csv` file\n",
    "import wget\n",
    "wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = spark.read.option(\"header\",\"true\").csv(\"employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---+----------+\n",
      "|Emp_No| Emp_Name|Salary|Age|Department|\n",
      "+------+---------+------+---+----------+\n",
      "|   198|   Donald|  2600| 29|        IT|\n",
      "|   199|  Douglas|  2600| 34|     Sales|\n",
      "|   200| Jennifer|  4400| 36| Marketing|\n",
      "|   201|  Michael| 13000| 32|        IT|\n",
      "|   202|      Pat|  6000| 39|        HR|\n",
      "|   203|    Susan|  6500| 36| Marketing|\n",
      "|   204|  Hermann| 10000| 29|   Finance|\n",
      "|   205|  Shelley| 12008| 33|   Finance|\n",
      "|   206|  William|  8300| 37|        IT|\n",
      "|   100|   Steven| 24000| 39|        IT|\n",
      "|   101|    Neena| 17000| 27|     Sales|\n",
      "|   102|      Lex| 17000| 37| Marketing|\n",
      "|   103|Alexander|  9000| 39| Marketing|\n",
      "|   104|    Bruce|  6000| 38|        IT|\n",
      "|   105|    David|  4800| 39|        IT|\n",
      "|   106|    Valli|  4800| 38|     Sales|\n",
      "|   107|    Diana|  4200| 35|     Sales|\n",
      "|   108|    Nancy| 12008| 28|     Sales|\n",
      "|   109|   Daniel|  9000| 35|        HR|\n",
      "|   110|     John|  8200| 31| Marketing|\n",
      "+------+---------+------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**defining schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df_schema = StructType([\n",
    "    StructField(\"Emp_no\", StringType(),nullable=True),\n",
    "    StructField(\"Emp_name\",StringType(),True),\n",
    "    StructField(\"Salary\",IntegerType(),True),\n",
    "    StructField(\"Age\",IntegerType(),True),\n",
    "    StructField(\"Department\",StringType(),True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Emp_no: string (nullable = true)\n",
      " |-- Emp_name: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df = spark.read.option(\"header\",\"true\").schema(employees_df_schema).csv(\"employees.csv\")\n",
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creating temp view and using sparkql**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.createTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**age >30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----------+\n",
      "|Emp_no|Emp_name|Salary|Age|Department|\n",
      "+------+--------+------+---+----------+\n",
      "|   199| Douglas|  2600| 34|     Sales|\n",
      "|   200|Jennifer|  4400| 36| Marketing|\n",
      "|   201| Michael| 13000| 32|        IT|\n",
      "|   202|     Pat|  6000| 39|        HR|\n",
      "|   203|   Susan|  6500| 36| Marketing|\n",
      "+------+--------+------+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees WHERE age >30 \").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**avg salary by dpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|avg_salary|Department|\n",
      "+----------+----------+\n",
      "|   5492.92|     Sales|\n",
      "|    5837.5|        HR|\n",
      "|    5730.8|   Finance|\n",
      "|   6633.33| Marketing|\n",
      "|    7400.0|        IT|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\" SELECT ROUND(AVG(Salary),2) as avg_salary, Department FROM employees GROUP BY Department\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filter department IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----------+\n",
      "|Emp_no|Emp_name|Salary|Age|Department|\n",
      "+------+--------+------+---+----------+\n",
      "|   198|  Donald|  2600| 29|        IT|\n",
      "|   201| Michael| 13000| 32|        IT|\n",
      "|   206| William|  8300| 37|        IT|\n",
      "|   100|  Steven| 24000| 39|        IT|\n",
      "|   104|   Bruce|  6000| 38|        IT|\n",
      "|   105|   David|  4800| 39|        IT|\n",
      "|   111|  Ismael|  7700| 32|        IT|\n",
      "|   129|   Laura|  3300| 38|        IT|\n",
      "|   132|      TJ|  2100| 34|        IT|\n",
      "|   136|   Hazel|  2200| 29|        IT|\n",
      "+------+--------+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.filter(\"Department =='IT'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,round,max,avg,sum,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----------+------------------+\n",
      "|Emp_no|Emp_name|Salary|Age|Department|salary_after_bonus|\n",
      "+------+--------+------+---+----------+------------------+\n",
      "|   198|  Donald|  2600| 29|        IT|2860.0000000000005|\n",
      "|   199| Douglas|  2600| 34|     Sales|2860.0000000000005|\n",
      "|   200|Jennifer|  4400| 36| Marketing|            4840.0|\n",
      "+------+--------+------+---+----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df = employees_df.withColumn(\"salary_after_bonus\",col(\"Salary\")*1.10)\n",
    "\n",
    "employees_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|Age|max(Salary)|\n",
      "+---+-----------+\n",
      "| 31|       8200|\n",
      "| 34|       7800|\n",
      "| 28|      12008|\n",
      "+---+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.groupBy(\"Age\").agg(max(\"Salary\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**self join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
      "|Emp_no| Emp_name|Salary|Age|Department|salary_after_bonus| Emp_name|Salary|Age|Department|salary_after_bonus|\n",
      "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
      "|   198|   Donald|  2600| 29|        IT|2860.0000000000005|   Donald|  2600| 29|        IT|2860.0000000000005|\n",
      "|   199|  Douglas|  2600| 34|     Sales|2860.0000000000005|  Douglas|  2600| 34|     Sales|2860.0000000000005|\n",
      "|   200| Jennifer|  4400| 36| Marketing|            4840.0| Jennifer|  4400| 36| Marketing|            4840.0|\n",
      "|   201|  Michael| 13000| 32|        IT|14300.000000000002|  Michael| 13000| 32|        IT|14300.000000000002|\n",
      "|   202|      Pat|  6000| 39|        HR| 6600.000000000001|      Pat|  6000| 39|        HR| 6600.000000000001|\n",
      "|   203|    Susan|  6500| 36| Marketing| 7150.000000000001|    Susan|  6500| 36| Marketing| 7150.000000000001|\n",
      "|   204|  Hermann| 10000| 29|   Finance|           11000.0|  Hermann| 10000| 29|   Finance|           11000.0|\n",
      "|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|  Shelley| 12008| 33|   Finance|13208.800000000001|\n",
      "|   206|  William|  8300| 37|        IT|            9130.0|  William|  8300| 37|        IT|            9130.0|\n",
      "|   100|   Steven| 24000| 39|        IT|26400.000000000004|   Steven| 24000| 39|        IT|26400.000000000004|\n",
      "|   101|    Neena| 17000| 27|     Sales|           18700.0|    Neena| 17000| 27|     Sales|           18700.0|\n",
      "|   102|      Lex| 17000| 37| Marketing|           18700.0|      Lex| 17000| 37| Marketing|           18700.0|\n",
      "|   103|Alexander|  9000| 39| Marketing|            9900.0|Alexander|  9000| 39| Marketing|            9900.0|\n",
      "|   104|    Bruce|  6000| 38|        IT| 6600.000000000001|    Bruce|  6000| 38|        IT| 6600.000000000001|\n",
      "|   105|    David|  4800| 39|        IT|            5280.0|    David|  4800| 39|        IT|            5280.0|\n",
      "|   106|    Valli|  4800| 38|     Sales|            5280.0|    Valli|  4800| 38|     Sales|            5280.0|\n",
      "|   107|    Diana|  4200| 35|     Sales|            4620.0|    Diana|  4200| 35|     Sales|            4620.0|\n",
      "|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|    Nancy| 12008| 28|     Sales|13208.800000000001|\n",
      "|   109|   Daniel|  9000| 35|        HR|            9900.0|   Daniel|  9000| 35|        HR|            9900.0|\n",
      "|   110|     John|  8200| 31| Marketing|            9020.0|     John|  8200| 31| Marketing|            9020.0|\n",
      "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.join(employees_df,'Emp_no','inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**average age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(Age)|\n",
      "+--------+\n",
      "|   33.56|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "employees_df.agg(avg(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|sum(Salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|      71408|\n",
      "|        HR|      46700|\n",
      "|   Finance|      57308|\n",
      "| Marketing|      59700|\n",
      "|        IT|      74000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.groupBy(\"Department\").agg(sum(\"Salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort Data by Age and Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---+----------+------------------+\n",
      "|Emp_no| Emp_name|Salary|Age|Department|salary_after_bonus|\n",
      "+------+---------+------+---+----------+------------------+\n",
      "|   137|   Renske|  3600| 26| Marketing|3960.0000000000005|\n",
      "|   101|    Neena| 17000| 27|     Sales|           18700.0|\n",
      "|   114|      Den| 11000| 27|   Finance|12100.000000000002|\n",
      "|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|\n",
      "|   130|    Mozhe|  2800| 28| Marketing|3080.0000000000005|\n",
      "|   126|    Irene|  2700| 28|        HR|2970.0000000000005|\n",
      "|   204|  Hermann| 10000| 29|   Finance|           11000.0|\n",
      "|   115|Alexander|  3100| 29|   Finance|3410.0000000000005|\n",
      "|   134|  Michael|  2900| 29|     Sales|3190.0000000000005|\n",
      "|   198|   Donald|  2600| 29|        IT|2860.0000000000005|\n",
      "|   140|   Joshua|  2500| 29|   Finance|            2750.0|\n",
      "|   136|    Hazel|  2200| 29|        IT|            2420.0|\n",
      "|   120|  Matthew|  8000| 30|        HR|            8800.0|\n",
      "|   110|     John|  8200| 31| Marketing|            9020.0|\n",
      "|   127|    James|  2400| 31|        HR|            2640.0|\n",
      "|   201|  Michael| 13000| 32|        IT|14300.000000000002|\n",
      "|   111|   Ismael|  7700| 32|        IT|            8470.0|\n",
      "|   119|    Karen|  2500| 32|   Finance|            2750.0|\n",
      "|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|\n",
      "|   124|    Kevin|  5800| 33| Marketing| 6380.000000000001|\n",
      "+------+---------+------+---+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.sort(\"Age\",\"Salary\",ascending=[True,False]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**employee by dpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|Department|count(Emp_no)|\n",
      "+----------+-------------+\n",
      "|     Sales|           13|\n",
      "|        HR|            8|\n",
      "|   Finance|           10|\n",
      "| Marketing|            9|\n",
      "|        IT|           10|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.groupBy(\"Department\").agg(count(\"Emp_no\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**employee name has o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+---+----------+------------------+\n",
      "|Emp_no|   Emp_name|Salary|Age|Department|salary_after_bonus|\n",
      "+------+-----------+------+---+----------+------------------+\n",
      "|   198|     Donald|  2600| 29|        IT|2860.0000000000005|\n",
      "|   199|    Douglas|  2600| 34|     Sales|2860.0000000000005|\n",
      "|   110|       John|  8200| 31| Marketing|            9020.0|\n",
      "|   112|Jose Manuel|  7800| 34|        HR|            8580.0|\n",
      "|   130|      Mozhe|  2800| 28| Marketing|3080.0000000000005|\n",
      "|   133|      Jason|  3300| 38|     Sales|3630.0000000000005|\n",
      "|   139|       John|  2700| 36|     Sales|2970.0000000000005|\n",
      "|   140|     Joshua|  2500| 29|   Finance|            2750.0|\n",
      "+------+-----------+------+---+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.filter(employees_df[\"Emp_name\"].like(\"%o%\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
